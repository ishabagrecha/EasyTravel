{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31d9a4c9",
      "metadata": {
        "origin_pos": 0,
        "id": "31d9a4c9"
      },
      "source": [
        "# Using Jupyter Notebooks\n",
        ":label:`sec_jupyter`\n",
        "\n",
        "\n",
        "This section describes how to edit and run the code\n",
        "in each section of this book\n",
        "using the Jupyter Notebook. Make sure you have\n",
        "installed Jupyter and downloaded the\n",
        "code as described in\n",
        ":ref:`chap_installation`.\n",
        "If you want to know more about Jupyter see the excellent tutorial in\n",
        "their [documentation](https://jupyter.readthedocs.io/en/latest/).\n",
        "\n",
        "\n",
        "## Editing and Running the Code Locally\n",
        "\n",
        "Suppose that the local path of the book's code is `xx/yy/d2l-en/`. Use the shell to change the directory to this path (`cd xx/yy/d2l-en`) and run the command `jupyter notebook`. If your browser does not do this automatically, open http://localhost:8888 and you will see the interface of Jupyter and all the folders containing the code of the book, as shown in :numref:`fig_jupyter00`.\n",
        "\n",
        "![The folders containing the code of this book.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter00.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter00`\n",
        "\n",
        "\n",
        "You can access the notebook files by clicking on the folder displayed on the webpage.\n",
        "They usually have the suffix \".ipynb\".\n",
        "For the sake of brevity, we create a temporary \"test.ipynb\" file.\n",
        "The content displayed after you click it is\n",
        "shown in :numref:`fig_jupyter01`.\n",
        "This notebook includes a markdown cell and a code cell. The content in the markdown cell includes \"This Is a Title\" and \"This is text.\".\n",
        "The code cell contains two lines of Python code.\n",
        "\n",
        "![Markdown and code cells in the \"text.ipynb\" file.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter01.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter01`\n",
        "\n",
        "\n",
        "Double click on the markdown cell to enter edit mode.\n",
        "Add a new text string \"Hello world.\" at the end of the cell, as shown in :numref:`fig_jupyter02`.\n",
        "\n",
        "![Edit the markdown cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter02.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter02`\n",
        "\n",
        "\n",
        "As demonstrated in :numref:`fig_jupyter03`,\n",
        "click \"Cell\" $\\rightarrow$ \"Run Cells\" in the menu bar to run the edited cell.\n",
        "\n",
        "![Run the cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter03.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter03`\n",
        "\n",
        "After running, the markdown cell is shown in :numref:`fig_jupyter04`.\n",
        "\n",
        "![The markdown cell after running.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter04.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter04`\n",
        "\n",
        "\n",
        "Next, click on the code cell. Multiply the elements by 2 after the last line of code, as shown in :numref:`fig_jupyter05`.\n",
        "\n",
        "![Edit the code cell.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter05.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter05`\n",
        "\n",
        "\n",
        "You can also run the cell with a shortcut (\"Ctrl + Enter\" by default) and obtain the output result from :numref:`fig_jupyter06`.\n",
        "\n",
        "![Run the code cell to obtain the output.](https://github.com/d2l-ai/d2l-en-colab/blob/master/img/jupyter06.png?raw=1)\n",
        ":width:`600px`\n",
        ":label:`fig_jupyter06`\n",
        "\n",
        "\n",
        "When a notebook contains more cells, we can click \"Kernel\" $\\rightarrow$ \"Restart & Run All\" in the menu bar to run all the cells in the entire notebook. By clicking \"Help\" $\\rightarrow$ \"Edit Keyboard Shortcuts\" in the menu bar, you can edit the shortcuts according to your preferences.\n",
        "\n",
        "## Advanced Options\n",
        "\n",
        "Beyond local editing two things are quite important: editing the notebooks in the markdown format and running Jupyter remotely.\n",
        "The latter matters when we want to run the code on a faster server.\n",
        "The former matters since Jupyter's native ipynb format stores a lot of auxiliary data that is\n",
        "irrelevant to the content,\n",
        "mostly related to how and where the code is run.\n",
        "This is confusing for Git, making\n",
        "reviewing contributions very difficult.\n",
        "Fortunately there is an alternative---native editing in the markdown format.\n",
        "\n",
        "### Markdown Files in Jupyter\n",
        "\n",
        "If you wish to contribute to the content of this book, you need to modify the\n",
        "source file (md file, not ipynb file) on GitHub.\n",
        "Using the notedown plugin we\n",
        "can modify notebooks in the md format directly in Jupyter.\n",
        "\n",
        "\n",
        "First, install the notedown plugin, run the Jupyter Notebook, and load the plugin:\n",
        "\n",
        "```\n",
        "pip install d2l-notedown  # You may need to uninstall the original notedown.\n",
        "jupyter notebook --NotebookApp.contents_manager_class='notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "You may also turn on the notedown plugin by default whenever you run the Jupyter Notebook.\n",
        "First, generate a Jupyter Notebook configuration file (if it has already been generated, you can skip this step).\n",
        "\n",
        "```\n",
        "jupyter notebook --generate-config\n",
        "```\n",
        "\n",
        "Then, add the following line to the end of the Jupyter Notebook configuration file (for Linux or macOS, usually in the path `~/.jupyter/jupyter_notebook_config.py`):\n",
        "\n",
        "```\n",
        "c.NotebookApp.contents_manager_class = 'notedown.NotedownContentsManager'\n",
        "```\n",
        "\n",
        "After that, you only need to run the `jupyter notebook` command to turn on the notedown plugin by default.\n",
        "\n",
        "### Running Jupyter Notebooks on a Remote Server\n",
        "\n",
        "Sometimes, you may want to run Jupyter notebooks on a remote server and access it through a browser on your local computer. If Linux or macOS is installed on your local machine (Windows can also support this function through third-party software such as PuTTY), you can use port forwarding:\n",
        "\n",
        "```\n",
        "ssh myserver -L 8888:localhost:8888\n",
        "```\n",
        "\n",
        "The above string `myserver` is the address of the remote server.\n",
        "Then we can use http://localhost:8888 to access the remote server `myserver` that runs Jupyter notebooks. We will detail on how to run Jupyter notebooks on AWS instances\n",
        "later in this appendix.\n",
        "\n",
        "### Timing\n",
        "\n",
        "We can use the `ExecuteTime` plugin to time the execution of each code cell in Jupyter notebooks.\n",
        "Use the following commands to install the plugin:\n",
        "\n",
        "```\n",
        "pip install jupyter_contrib_nbextensions\n",
        "jupyter contrib nbextension install --user\n",
        "jupyter nbextension enable execute_time/ExecuteTime\n",
        "```\n",
        "\n",
        "## Summary\n",
        "\n",
        "* Using the Jupyter Notebook tool, we can edit, run, and contribute to each section of the book.\n",
        "* We can run Jupyter notebooks on remote servers using port forwarding.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Edit and run the code in this book with the Jupyter Notebook on your local machine.\n",
        "1. Edit and run the code in this book with the Jupyter Notebook *remotely* via port forwarding.\n",
        "1. Compare the running time of the operations $\\mathbf{A}^\\top \\mathbf{B}$ and $\\mathbf{A} \\mathbf{B}$ for two square matrices in $\\mathbb{R}^{1024 \\times 1024}$. Which one is faster?\n",
        "\n",
        "\n",
        "[Discussions](https://discuss.d2l.ai/t/421)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import r2_score, mean_squared_error, roc_auc_score, precision_score, recall_score\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "df=pd.read_csv(\"hr_analytics_data.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJpnQUSu8Woj",
        "outputId": "283c7d14-8615-4c90-d0c3-9fc294169bc7"
      },
      "id": "NJpnQUSu8Woj",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   EmployeeID  Age  YearsAtCompany  TotalWorkingYears  MonthlyIncome  \\\n",
            "0           1   28               3                  5           4000   \n",
            "1           2   35               7                 10           6500   \n",
            "2           3   41              10                 18           8200   \n",
            "3           4   30               2                  4           3700   \n",
            "4           5   50              20                 25          12000   \n",
            "\n",
            "   PercentSalaryHike  PerformanceRating  JobInvolvement  \\\n",
            "0                 15                  3               3   \n",
            "1                 12                  4               2   \n",
            "2                 18                  3               4   \n",
            "3                 13                  3               3   \n",
            "4                 11                  4               3   \n",
            "\n",
            "   TrainingTimesLastYear  YearsSinceLastPromotion OverTime Attrition  \n",
            "0                      2                        1      Yes        No  \n",
            "1                      3                        2       No        No  \n",
            "2                      1                        4      Yes       Yes  \n",
            "3                      3                        0       No        No  \n",
            "4                      2                        6      Yes       Yes  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c in df.select_dtypes(include=['object']).columns:\n",
        "    df[c] = LabelEncoder().fit_transform(df[c])\n"
      ],
      "metadata": {
        "id": "IOSWl91DUsQ0"
      },
      "id": "IOSWl91DUsQ0",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['NT'] = np.log(df['YearsAtCompany'] + 1) / np.log(df['TotalWorkingYears'] + 2)\n",
        "df['AS'] = df['MonthlyIncome'] * (df['PercentSalaryHike'] / 100)\n",
        "df['WI'] = (df['PerformanceRating'] * df['JobInvolvement']) / (1 + df['TrainingTimesLastYear'])\n",
        "df['AT'] = ((df['OverTime'] == \"Yes\").astype(int)) * (1 - df['NT']) * (1 + df['YearsSinceLastPromotion'] / (1 + df['AS']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKs8C0B68tGz",
        "outputId": "ea6cf80f-b41e-4365-8104-3e14f57206ef"
      },
      "id": "TKs8C0B68tGz",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Now apply the KNNImputer\n",
        "imputer=KNNImputer(n_neighbors=5)\n",
        "df[:]=imputer.fit_transform(df)"
      ],
      "metadata": {
        "id": "ogKmBYIr8tZI"
      },
      "id": "ogKmBYIr8tZI",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=QuantileTransformer(output_distribution='normal')\n",
        "df[:]=scaler.fit_transform(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf_fo2D48tcP",
        "outputId": "29587efd-661d-4deb-fada-977cf627e0fe"
      },
      "id": "Pf_fo2D48tcP",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py:2829: UserWarning: n_quantiles (1000) is greater than the total number of samples (10). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-5.19933758 -1.22064035 -0.76470967 -0.4307273  -0.1397103   0.1397103\n",
            "  0.4307273   0.76470967  1.22064035  5.19933758]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-5.19933758 -0.1397103   0.4307273  -0.76470967  5.19933758  1.22064035\n",
            " -1.22064035  0.1397103  -0.4307273   0.76470967]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.22064035 -0.1397103   0.76470967 -5.19933758  5.19933758  1.22064035\n",
            " -0.76470967  0.1397103  -0.4307273   0.4307273 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.22064035 -0.1397103   0.4307273  -5.19933758  5.19933758  1.22064035\n",
            " -0.76470967  0.1397103  -0.4307273   0.76470967]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.22064035 -0.1397103   0.4307273  -5.19933758  5.19933758  1.22064035\n",
            " -0.76470967  0.1397103  -0.4307273   0.76470967]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.76470967 -0.4307273   5.19933758  0.         -0.76470967  0.4307273\n",
            "  1.22064035 -1.22064035 -5.19933758  0.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-5.19933758  5.19933758 -5.19933758 -5.19933758  5.19933758  5.19933758\n",
            " -5.19933758  5.19933758 -5.19933758 -5.19933758]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.1397103  -5.19933758  5.19933758 -0.1397103  -0.1397103   5.19933758\n",
            " -5.19933758 -0.1397103  -0.1397103   5.19933758]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.28221615  0.76470967 -5.19933758  0.76470967 -0.28221615  1.22064035\n",
            " -0.28221615  5.19933758 -0.28221615 -5.19933758]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.76470967  0.1397103   1.22064035 -5.19933758  5.19933758  0.76470967\n",
            " -0.76470967  0.1397103  -0.76470967  0.1397103 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 5.19933758 -5.19933758  5.19933758 -5.19933758  5.19933758 -5.19933758\n",
            "  5.19933758 -5.19933758 -5.19933758  5.19933758]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n",
            "/tmp/ipython-input-2665297327.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-5.19933758 -5.19933758  5.19933758 -5.19933758  5.19933758 -5.19933758\n",
            " -5.19933758 -5.19933758  5.19933758 -5.19933758]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df[:]=scaler.fit_transform(df)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr=df.corr()"
      ],
      "metadata": {
        "id": "LsHGeMbw8tiZ"
      },
      "id": "LsHGeMbw8tiZ",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop=[col for col in corr.columns if any(corr[col]<0.85)]\n",
        "df_reduced=df.drop(columns=set(to_drop),errors='ignore')\n"
      ],
      "metadata": {
        "id": "8MoFkB5u8tlk"
      },
      "id": "8MoFkB5u8tlk",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mz5doWsMfnx_"
      },
      "id": "mz5doWsMfnx_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if df_reduced has more than one column before calculating VIF\n",
        "if df_reduced.shape[1] > 1:\n",
        "    vif=pd.DataFrame()\n",
        "    vif[\"Feature\"]=df_reduced.columns\n",
        "    vif[\"VIF\"]=[variance_inflation_factor(df_reduced.values,i)for i in range(df_reduced.shape[1])]\n",
        "    print(\"VIF\",vif)\n",
        "else:\n",
        "    print(\"df_reduced has only one column or is empty. Cannot calculate VIF.\")\n",
        "    vif = pd.DataFrame({\"Feature\": df_reduced.columns, \"VIF\": [float('inf')] * df_reduced.shape[1]}) # Create a dummy vif dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFGWXKfCN7mi",
        "outputId": "ff635153-5fb8-469b-f974-557a77980170"
      },
      "id": "eFGWXKfCN7mi",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_reduced has only one column or is empty. Cannot calculate VIF.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final=df_reduced.drop(columns=vif[vif[\"VIF\"]>10][\"Feature\"])\n",
        "print(\"\\n✅ Final features kept for modeling:\\n\", list(df_final.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzpxObaI8tow",
        "outputId": "b80561ad-90ce-4dcc-b1bf-772ab7fa42fe"
      },
      "id": "HzpxObaI8tow",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Final features kept for modeling:\n",
            " []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3V8AcV07pA8y"
      },
      "id": "3V8AcV07pA8y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "X = df.drop('AS', axis=1, errors='ignore')\n",
        "Y = df['AS']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, Y_train)\n",
        "Y_pred = lr.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "rE68Pbmc8tr9",
        "outputId": "3eed5f9d-69a0-4fe2-aab0-1c0250107b89"
      },
      "id": "rE68Pbmc8tr9",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3066182428.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= PHASE 3 =======\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import r2_score, mean_squared_error, precision_score, recall_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# 1. Linear Regression (Target = AS)\n",
        "# -------------------------\n",
        "X = df_final.drop('AS', axis=1, errors='ignore')\n",
        "y = df_final['AS']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print(\"\\nLinear Regression Results:\")\n",
        "print(\"R2 Score:\", round(r2_score(y_test, y_pred), 3))\n",
        "print(\"RMSE:\", round(np.sqrt(mean_squared_error(y_test, y_pred)), 3))\n",
        "\n",
        "# -------------------------\n",
        "# 2. Naive Bayes (Target = OverTime)\n",
        "# -------------------------\n",
        "X = df_final.drop('OverTime', axis=1, errors='ignore')\n",
        "y = df_final['OverTime']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "y_prob = nb.predict_proba(X_test)\n",
        "\n",
        "print(\"\\nNaive Bayes Results:\")\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred, average='macro'), 3))\n",
        "print(\"Recall:\", round(recall_score(y_test, y_pred, average='macro'), 3))\n",
        "print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob[:,1]), 3))\n",
        "print(\"\\nPosterior Probabilities (first 3):\\n\", y_prob[:3])\n",
        "\n",
        "# -------------------------\n",
        "# 3. Decision Tree (Target = Attrition)\n",
        "# -------------------------\n",
        "X = df_final.drop('Attrition', axis=1, errors='ignore')\n",
        "y = df_final['Attrition']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=6)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "y_prob = dt.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\nDecision Tree Results:\")\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred, average='macro'), 3))\n",
        "print(\"Recall:\", round(recall_score(y_test, y_pred, average='macro'), 3))\n",
        "print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob), 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ss4unEO8tvS",
        "outputId": "63337ed7-79ff-45a0-b8fe-cbd4ebc8f4ef"
      },
      "id": "_ss4unEO8tvS",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIS04FMdslOQ"
      },
      "id": "tIS04FMdslOQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}